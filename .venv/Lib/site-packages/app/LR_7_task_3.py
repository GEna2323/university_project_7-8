import numpy as np
from sklearn import linear_model
import sklearn.metrics as sm
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

#Input data
input_file = 'data_multivar_regr.txt'
data = np.loadtxt(input_file, delimiter=',')
X, y = data[:, :-1], data[:, -1]

#Input features
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)

#Creating regressor
regressor = linear_model.LinearRegression()
regressor.fit(X_train, y_train)

#Prediction the result
y_test_pred = regressor.predict(X_test)

#Check mae and etc
print("\nLinear regression performance:")
print("Mean Absolute Error =",
round(sm.mean_absolute_error(y_test, y_test_pred), 2))
print("Mean Squared Error =",
round(sm.mean_squared_error(y_test, y_test_pred), 2))
print("Median Absolute Error =",
round(sm.median_absolute_error(y_test, y_test_pred), 2))
print("Explain Variance Score =",
round(sm.explained_variance_score(y_test, y_test_pred), 2))
print("R2 score =",
round(sm.r2_score(y_test, y_test_pred), 2))

#Polinamial regression
polynomial = PolynomialFeatures(degree=10)
X_train_transformed = polynomial.fit_transform(X_train)

datapoint = [[7.73, 6.35, 5.56]]
poly_datapoint = polynomial.fit_transform(datapoint)

poly_linear_model = linear_model.LinearRegression()
poly_linear_model.fit(X_train_transformed, y_train)

print("\nLinear regession:\n",
regressor.predict(datapoint))
print("\nPolynomial regession:\n",
poly_linear_model.predict(poly_datapoint))

#Plot
plt.scatter(y_test, y_test_pred, color='green')
min_val = min(min(y_test), min(y_test_pred))
max_val = max(max(y_test), max(y_test_pred))
plt.plot([min_val, max_val], [min_val, max_val], color='black', linewidth=2)
plt.xlabel("y_test")
plt.ylabel("y_test_pred")
plt.show()